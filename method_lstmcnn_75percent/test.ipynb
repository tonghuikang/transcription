{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2000\n",
    "height = 108\n",
    "width = 108\n",
    "steps = 20\n",
    "spec_list = spectrums_index[:num_samples]\n",
    "labe_list = labels_index[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_index = np.array(glob.glob('../preparations/spectrograms/*'))\n",
    "labels_index = np.array(glob.glob('../preparations/labels/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = BatchNormalization()(cnn_inputs)\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_score(model, cnn_test, lstm_test, y_test):\n",
    "    prediction = model.predict([cnn_test, lstm_test])\n",
    "    wrong = 0\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if abs(prediction[i][j] - y_test[i][j]) > 0.5:\n",
    "                wrong += 1\n",
    "                break\n",
    "    print('{} samples are loaded for testing'.format(prediction.shape[0]))\n",
    "    print('{} testing samples are predicted wrong'.format(wrong))\n",
    "    accuracy = 1 - wrong/(prediction.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_model(spectrum_list, labels_list, order, num, start, ending):\n",
    "    lstm_output = []\n",
    "    cnn_output = []\n",
    "    y_train = []\n",
    "    \n",
    "    import time\n",
    "    start_ = time.time()\n",
    "\n",
    "    for file in order[num][start:ending]:\n",
    "        spectrum = np.load(spectrum_list[file])\n",
    "        labels = np.load(labels_list[file])\n",
    "        \n",
    "        _lstm = np.zeros((20, 24))\n",
    "        for count, i in enumerate(labels):\n",
    "            _cnn = spectrum[:, 27*count:108+27*count]\n",
    "            if _cnn.shape == (height, width):\n",
    "                lstm_output.append(_lstm)\n",
    "                cnn_output.append(_cnn.reshape((height, width, 1)))\n",
    "                y_train.append(i)\n",
    "        \n",
    "            _lstm = _lstm[1:, :]\n",
    "            _lstm = np.append(_lstm, i.reshape((1, 24)), axis=0)\n",
    "        \n",
    "    lstm_inputs = np.array(lstm_output)\n",
    "    cnn_inputs = np.array(cnn_output)\n",
    "    labels_inputs = np.array(y_train)\n",
    "    print(time.time()-start_)\n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the CV sets\n",
    "kf = KFold(n_splits=3, random_state=7)\n",
    "\n",
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(num_samples)\n",
    "\n",
    "for x, y in kf.split(range(num_samples)):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5931005477905273\n"
     ]
    }
   ],
   "source": [
    "lstm_test, cnn_test, labels_test = inputs_to_model(spec_list, labe_list, test_order, 0, 0, test_order[0].shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier_1(optimizer='adam')\n",
    "classifier.load_weights('weights/weight-75overlap-model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82075 samples are loaded for testing\n",
      "9509 testing samples are predicted wrong\n"
     ]
    }
   ],
   "source": [
    "accuracy = load_test_score(classifier, lstm_test, cnn_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8841425525434055"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
