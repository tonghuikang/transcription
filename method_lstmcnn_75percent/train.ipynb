{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_index = np.array(glob.glob('E:/note_detection/spectrogram/*'))\n",
    "labels_index = np.array(glob.glob('E:/note_detection/label/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for i in range(len(labels_index)):\n",
    "    num = np.load(spectrums_index[i]).shape[1]//np.load(labels_index[i]).shape[0]\n",
    "    if num == 24:\n",
    "        count += 1\n",
    "    elif num != 23:\n",
    "        print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "height = 108\n",
    "width = 108\n",
    "steps = 20\n",
    "spec_list = spectrums_index[:num_samples]\n",
    "labe_list = labels_index[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=12, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_cnn_lstm_input_and_target_label(spectrogram, label):\n",
    "    length = np.shape(spectrogram)[1] - 108\n",
    "    random_point = np.random.randint(0,length)\n",
    "\n",
    "    cnn_input = spectrogram[:,random_point:random_point+108]\n",
    "    lstm_input = label[random_point//27:random_point//27+20,:]\n",
    "    target_label = label[random_point//27+20,:]\n",
    "        \n",
    "    return cnn_input, lstm_input, target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = BatchNormalization()(cnn_inputs)\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_3(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(cnn_inputs)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(num_samples)\n",
    "\n",
    "for x, y in kf.split(range(num_samples)):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_model(spectrum_list, labels_list, order, num, start, ending):\n",
    "    lstm_output = []\n",
    "    cnn_output = []\n",
    "    y_train = []\n",
    "    \n",
    "    import time\n",
    "    start_ = time.time()\n",
    "\n",
    "    for file in order[num][start:ending]:\n",
    "        spectrum = np.load(spectrum_list[file])\n",
    "        labels = np.load(labels_list[file])\n",
    "        gap = spectrum.shape[1] // labels.shape[0]\n",
    "        \n",
    "        _lstm = np.zeros((20, 24))\n",
    "        for count, i in enumerate(labels):\n",
    "            _cnn = spectrum[:, gap*count:108+gap*count]\n",
    "            if _cnn.shape == (height, width):\n",
    "                lstm_output.append(_lstm)\n",
    "                cnn_output.append(_cnn.reshape((height, width, 1)))\n",
    "                y_train.append(i)\n",
    "        \n",
    "            _lstm = _lstm[1:, :]\n",
    "            _lstm = np.append(_lstm, i.reshape((1, 24)), axis=0)\n",
    "        \n",
    "    lstm_inputs = np.array(lstm_output)\n",
    "    cnn_inputs = np.array(cnn_output)\n",
    "    labels_inputs = np.array(y_train)\n",
    "    print(time.time()-start_)\n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_database(glob_spectrogram, glob_label, times=10):\n",
    "    cnn_inputs = []\n",
    "    lstm_inputs = []\n",
    "    labels_inputs = []\n",
    "    for spectrogram_,label_ in zip(glob_spectrogram,glob_label):\n",
    "        spectrogram = np.load(spectrogram_)\n",
    "        label = np.load(label_)\n",
    "        for i in range(times):\n",
    "            cnn_input, lstm_input, target_label = generate_random_cnn_lstm_input_and_target_label(spectrogram, label)\n",
    "            cnn_inputs.append(cnn_input)\n",
    "            lstm_inputs.append(lstm_input)\n",
    "            labels_inputs.append(target_label)\n",
    "    return np.array(cnn_inputs), np.array(lstm_inputs), np.array(labels_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_model_split(spectrum_list, labels_list, order, num, start, ending, times=10):\n",
    "    cnn_inputs, lstm_inputs, labels_inputs = generate_database(spectrum_list[order[num][start:ending]], \n",
    "                                                               labels_list[order[num][start:ending]], times)\n",
    "    cnn_inputs = cnn_inputs.reshape((cnn_inputs.shape[0], 108, 108, 1))\n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test, cnn_test, labels_test = inputs_to_model_split(spec_list, labe_list, test_order, 0, 0, test_order[0].shape[0]+1, times=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8340, 20, 24)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8340, 108, 108, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8340, 24)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_whole(classifier, num, name, spectrum_list, labels_list, epochs=100, batchsize=32, times=10):\n",
    "    lstm_inputs, cnn_inputs, labels_inputs = inputs_to_model_split(spectrum_list, labels_list, train_order, \n",
    "                                                             num, 0, train_order[num].shape[0]+1, times)\n",
    "\n",
    "    classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=epochs, batch_size=batchsize, verbose=1,\n",
    "                  validation_data = ([lstm_test, cnn_test], labels_test))\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)   \n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_part(classifier, num, name, spectrum_list, labels_list, epochs=100, batchsize=32, split=7):\n",
    "    \n",
    "    num_samples = train_order[num].shape[0]\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        print(\n",
    "           \"\"\"\n",
    "        \n",
    "        THIS IS EPOCH_{}\"\"\".format(j))\n",
    "        for i in range(split):\n",
    "            lstm_inputs, cnn_inputs, labels_inputs = inputs_to_model_split(spectrum_list, labels_list, train_order, \n",
    "                                                                     num, num_samples//split*i, num_samples//split*(i+1))\n",
    "\n",
    "            classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=1, batch_size=batchsize, verbose=1,\n",
    "                          validation_data = ([lstm_test, cnn_test], labels_test))\n",
    "            gc.collect()\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)   \n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91660 samples, validate on 8340 samples\n",
      "Epoch 1/10\n",
      "91660/91660 [==============================] - 159s 2ms/step - loss: 0.0370 - acc: 0.9876 - val_loss: 0.0246 - val_acc: 0.9917\n",
      "Epoch 2/10\n",
      "91660/91660 [==============================] - 154s 2ms/step - loss: 0.0229 - acc: 0.9920 - val_loss: 0.0227 - val_acc: 0.9925\n",
      "Epoch 3/10\n",
      "91660/91660 [==============================] - 157s 2ms/step - loss: 0.0197 - acc: 0.9930 - val_loss: 0.0246 - val_acc: 0.9923\n",
      "Epoch 4/10\n",
      "91660/91660 [==============================] - 154s 2ms/step - loss: 0.0179 - acc: 0.9935 - val_loss: 0.0210 - val_acc: 0.9931\n",
      "Epoch 5/10\n",
      "91660/91660 [==============================] - 159s 2ms/step - loss: 0.0167 - acc: 0.9939 - val_loss: 0.0216 - val_acc: 0.9924\n",
      "Epoch 6/10\n",
      "91660/91660 [==============================] - 157s 2ms/step - loss: 0.0157 - acc: 0.9941 - val_loss: 0.0198 - val_acc: 0.9931\n",
      "Epoch 7/10\n",
      "91660/91660 [==============================] - 157s 2ms/step - loss: 0.0149 - acc: 0.9944 - val_loss: 0.0195 - val_acc: 0.9934\n",
      "Epoch 8/10\n",
      "91660/91660 [==============================] - 157s 2ms/step - loss: 0.0142 - acc: 0.9947 - val_loss: 0.0218 - val_acc: 0.9928\n",
      "Epoch 9/10\n",
      "91660/91660 [==============================] - 158s 2ms/step - loss: 0.0138 - acc: 0.9947 - val_loss: 0.0193 - val_acc: 0.9930\n",
      "Epoch 10/10\n",
      "91660/91660 [==============================] - 158s 2ms/step - loss: 0.0131 - acc: 0.9950 - val_loss: 0.0248 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28194"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_3(optimizer=adam)\n",
    "train_test_whole(classifier, 0, 'weights/weight-24units-model1.hdf5', spec_list, labe_list, epochs=10, times=20)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91660 samples, validate on 8340 samples\n",
      "Epoch 1/10\n",
      "91660/91660 [==============================] - 140s 2ms/step - loss: 0.0377 - acc: 0.9873 - val_loss: 0.0238 - val_acc: 0.9918\n",
      "Epoch 2/10\n",
      "91660/91660 [==============================] - 136s 1ms/step - loss: 0.0228 - acc: 0.9920 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 3/10\n",
      "91660/91660 [==============================] - 135s 1ms/step - loss: 0.0193 - acc: 0.9931 - val_loss: 0.0185 - val_acc: 0.9935\n",
      "Epoch 4/10\n",
      "91660/91660 [==============================] - 135s 1ms/step - loss: 0.0171 - acc: 0.9937 - val_loss: 0.0229 - val_acc: 0.9928\n",
      "Epoch 5/10\n",
      "91660/91660 [==============================] - 138s 2ms/step - loss: 0.0158 - acc: 0.9941 - val_loss: 0.0180 - val_acc: 0.9940\n",
      "Epoch 6/10\n",
      "91660/91660 [==============================] - 138s 2ms/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.0182 - val_acc: 0.9936\n",
      "Epoch 7/10\n",
      "91660/91660 [==============================] - 140s 2ms/step - loss: 0.0137 - acc: 0.9948 - val_loss: 0.0199 - val_acc: 0.9933\n",
      "Epoch 8/10\n",
      "91660/91660 [==============================] - 140s 2ms/step - loss: 0.0127 - acc: 0.9951 - val_loss: 0.0193 - val_acc: 0.9938\n",
      "Epoch 9/10\n",
      "91660/91660 [==============================] - 140s 2ms/step - loss: 0.0122 - acc: 0.9952 - val_loss: 0.0187 - val_acc: 0.9936\n",
      "Epoch 10/10\n",
      "91660/91660 [==============================] - 141s 2ms/step - loss: 0.0116 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23088"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_1(optimizer=adam)\n",
    "train_test_whole(classifier, 0, 'weights/weight-24units-model2.hdf5', spec_list, labe_list, epochs=10, times=20)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \n",
      "        THIS IS EPOCH_0\n",
      "Train on 4580 samples, validate on 4170 samples\n",
      "Epoch 1/1\n",
      "4580/4580 [==============================] - 15s 3ms/step - loss: 0.0994 - acc: 0.9708 - val_loss: 0.0630 - val_acc: 0.9843\n",
      "Train on 4580 samples, validate on 4170 samples\n",
      "Epoch 1/1\n",
      "3072/4580 [===================>..........] - ETA: 2s - loss: 0.0525 - acc: 0.9848"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9884994408eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_test_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weight-24units-model1.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabe_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-cc69443b9d78>\u001b[0m in \u001b[0;36mtrain_test_part\u001b[1;34m(classifier, num, name, spectrum_list, labels_list, epochs, batchsize, split)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=1, batch_size=batchsize, verbose=1,\n\u001b[1;32m---> 15\u001b[1;33m                           validation_data = ([lstm_test, cnn_test], labels_test))\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_3(optimizer=adam)\n",
    "train_test_part(classifier, 0, 'weights/weight-24units-model1.hdf5', spec_list, labe_list, epochs=10, split=10)\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
